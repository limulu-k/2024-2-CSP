{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bd9a7b-0d48-45a5-a551-edcb9d562b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers는 이미 설치되어 있습니다.\n",
      "torch는 이미 설치되어 있습니다.\n",
      "openpyxl는 이미 설치되어 있습니다.\n",
      "pandas는 이미 설치되어 있습니다.\n",
      "konlpy는 이미 설치되어 있습니다.\n",
      "sentencepiece는 이미 설치되어 있습니다.\n",
      "모든 패키지 확인 완료.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# 설치할 라이브러리 목록\n",
    "required_packages = [\"transformers\", \"torch\", \"openpyxl\", \"pandas\", \"konlpy\", \"sentencepiece\"]\n",
    "\n",
    "# 패키지 설치 함수\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# 각 패키지에 대해 확인하고 설치\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "        print(f\"{package}는 이미 설치되어 있습니다.\")\n",
    "    except ImportError:\n",
    "        print(f\"{package}가 설치되어 있지 않습니다. 설치 중...\")\n",
    "        install(package)\n",
    "\n",
    "print(\"모든 패키지 확인 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2def2e-5a4d-42c6-ae8b-a3e16a62035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import pipeline, BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ff743f-8e33-4f5c-bd40-6cd8535885e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limul\\Desktop\\College\\2_grade\\2_semester\\전산통계학\\팀프로젝트\\workspace\\newsData\n",
      "['NewsResult_2000.xlsx']\n"
     ]
    }
   ],
   "source": [
    "dataPath = f\"{os.getcwd()}\\\\newsData\"\n",
    "print(dataPath)\n",
    "xlsxList = os.listdir(dataPath)\n",
    "print(xlsxList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f28cd0-6cd5-4ed2-9e60-e63bab21032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 라벨링 후 재 학습을 통한 데이터 정확도 향상 필요\n",
    "# 코드 아직 다 안짬 그냥 gpt 예시 코드임\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# 라벨링된 데이터 로드\n",
    "data_path = \"labeled_data.xlsx\"\n",
    "labeled_df = pd.read_excel(data_path)\n",
    "\n",
    "# 데이터셋 준비\n",
    "texts = labeled_df['content'].tolist()  # 본문 데이터\n",
    "labels = labeled_df['label'].tolist()    # 라벨 (예: 0: negative, 1: positive)\n",
    "\n",
    "# 데이터 분할 (훈련/검증)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n",
    "\n",
    "# 텍스트를 토큰화\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_dataset = NewsDataset(train_encodings, train_labels)\n",
    "val_dataset = NewsDataset(val_encodings, val_labels)\n",
    "\n",
    "# 모델 로드\n",
    "model = BertForSequenceClassification.from_pretrained(\"monologg/kobert\", num_labels=2)\n",
    "\n",
    "# 훈련 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Trainer 객체 생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "trainer.train()\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(\"./finetuned_kobert\")\n",
    "tokenizer.save_pretrained(\"./finetuned_kobert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d2a843-4720-4681-a6cf-293aba6765df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(ks,c):\n",
    "    # 본문과 키워드를 결합, row = [본문, 키워드(리스트)]\n",
    "    text = f\"{c} 키워드: {', '.join(ks)}\"\n",
    "    result = sentiment_analyzer(text)\n",
    "    return \"positive\" if result[0]['label'] == \"LABEL_0\" else \"negative\" # 'POSITIVE' 또는 'NEGATIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f086c06-6b7c-462d-8b46-ba8eae3ab2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\limul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limul\\Desktop\\College\\2_grade\\2_semester\\전산통계학\\팀프로젝트\\workspace\\newsData\\NewsResult_2000.xlsx\n",
      "제목: [연말 연초 볼만한 영화] '불후의 명작' 外\t결괏값 : negative\n",
      "제목: [동정]\t결괏값 : positive\n",
      "제목: [DJP회동 합의문]\t결괏값 : positive\n",
      "제목: [사진]선사유적지 도로변 주차금지\t결괏값 : positive\n",
      "제목: [사설] 새 SOFA와 한 미관계\t결괏값 : positive\n",
      "제목: ＂해양주권 확보와 어민생활보호에 중점 둘터＂\t결괏값 : positive\n",
      "제목: 오염물질 배출사업장 감시 위반업소 고발등 행정처분\t결괏값 : positive\n",
      "제목: 주유중 엔진정지 생활화 필요\t결괏값 : positive\n",
      "제목: 연말연시 극장 나들이 새해 밑그림 그려보자\t결괏값 : negative\n",
      "제목: 도막소식\t결괏값 : positive\n",
      "제목: 폐기물 매립장 추가조성 논란\t결괏값 : positive\n",
      "제목: 오염배출업소 단속\t결괏값 : positive\n",
      "제목: 지정폐기물 반입 논란\t결괏값 : positive\n",
      "제목: 강원 中企대상 선정 현대특수사료 환경부장관 표창 수상\t결괏값 : positive\n",
      "제목: 벤처, “기술력로 중무장 해외로 ”\t결괏값 : positive\n",
      "제목: [피플파워 NGO] '다음을 지키는 엄마모임'\t결괏값 : positive\n",
      "제목: 종교지도자들 신년사 발표\t결괏값 : positive\n",
      "제목: [TV 가이드/30일]SBS 송년특집 10대 가수 청백전\t결괏값 : negative\n",
      "제목: [SOFA 환경조항 전망]'환경법 존중' 실효성 논란여지\t결괏값 : positive\n",
      "제목: SOFA협상 한국수석대표 송민순 외교부북미국장\t결괏값 : positive\n",
      "제목: [강원]버려진 동물 사육장 '애신의 집' 철원이전 난항\t결괏값 : positive\n",
      "제목: [대구/경북]식수원 인근 공단추진 논란\t결괏값 : positive\n",
      "제목: [열린마당] 환경오염 줄이는 방법 구체적으로 알려줘야\t결괏값 : positive\n",
      "제목: [SOFA 개정협상] 무엇이 달라졌나\t결괏값 : positive\n",
      "제목: 겨울 들어 최고 한파 기록\t결괏값 : positive\n",
      "제목: <사설>5년만에 타결된 SOFA\t결괏값 : negative\n",
      "제목: SOFA 개정 타결 의미-'毒'은 빠졌지만 '덫'은 여전\t결괏값 : negative\n",
      "제목: 새영화/ 패밀리 맨 외\t결괏값 : positive\n",
      "제목: 오염 배출업소 무더기 적발\t결괏값 : positive\n",
      "제목: \"이번 개정 개악\"\t결괏값 : positive\n",
      "제목: SOFA 환경조항 내년 1월부터 논의\t결괏값 : positive\n",
      "제목: SOFA 환경조항 세부절차 내년 1월부터 논의\t결괏값 : positive\n",
      "제목: [건강] '아토피' 한방연고 나와\t결괏값 : positive\n",
      "제목: 기고 / 덜 쓰고 덜 버리는 생활부터\t결괏값 : negative\n",
      "제목: 부실 私學, 제도적 척결 방안을\t결괏값 : positive\n",
      "제목: SOFA 본질적 개선 없다\t결괏값 : positive\n",
      "제목: 《새영화》... 레드 플래닛\t결괏값 : negative\n",
      "제목: 음성 맹동면 인곡리 주민 꽃동네가족 “생존권 위협” 광업권 철회 촉구\t결괏값 : positive\n",
      "제목: 새해연휴 극장가로 나들이 갈까\t결괏값 : negative\n",
      "제목: SOFA 개정협상 타결\t결괏값 : positive\n",
      "제목: 인천 축제문화 활성화 더딘 걸음\t결괏값 : negative\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='openpyxl')\n",
    "\n",
    "dataPath = f\"{os.getcwd()}\\\\newsData\"\n",
    "xlsxList = os.listdir(dataPath)\n",
    "\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"monologg/kobert\", trust_remote_code=True)\n",
    "\n",
    "# 0:뉴스식별자,1:일자,2:언론사,3:기고자,4:제목,5:통합분류1,6:통합분류2,7:통합 분류3,8:사건/사고분류1,9:사건/사고분류2,10:사건/사고분류3,\n",
    "# 11:인물,12:위치,13:기관,14:키워드,15:특성추출(가중치순 상위 50개),16:본문,17:URL,18:분석제외여부\n",
    "\n",
    "\n",
    "for xl in xlsxList:\n",
    "    tmp = f\"{dataPath}\\\\{xl}\"\n",
    "    print(tmp)\n",
    "    df = pd.read_excel(tmp)\n",
    "    idx = 0\n",
    "    \n",
    "    for row in df.itertuples(index=False):\n",
    "        # print(f\"date: {row[1]}\\ttitle: {row[4]}\\tkeyword: {row[15]}\\tcontent: {row[16]}\")\n",
    "        keyWord = list(map(str,row[15].split(\",\")))\n",
    "        content = row[16]\n",
    "        print(f\"제목: {row[4]}\\t결괏값 : {analyze_sentiment(keyWord,content)}\")\n",
    "        if idx == 40:\n",
    "            break\n",
    "        idx += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
