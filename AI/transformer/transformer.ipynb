{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 경로 설정\n",
    "pollutants_path = '../../NewData/Weekly_Air_Pollutants.csv'\n",
    "weather_path = '../data_preprocessing/normalized_analyze_abnormal.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     84\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[1;32m---> 85\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     87\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\limul\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\limul\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\limul\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:3101\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target):\n\u001b[0;32m   3098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   3099\u001b[0m         mse_loss, (\u001b[38;5;28minput\u001b[39m, target), \u001b[38;5;28minput\u001b[39m, target, size_average\u001b[38;5;241m=\u001b[39msize_average, reduce\u001b[38;5;241m=\u001b[39mreduce, reduction\u001b[38;5;241m=\u001b[39mreduction\n\u001b[0;32m   3100\u001b[0m     )\n\u001b[1;32m-> 3101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m   3102\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   3103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()),\n\u001b[0;32m   3106\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   3107\u001b[0m     )\n\u001b[0;32m   3108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# Transformer 모델 정의\n",
    "class WeatherTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_model, nhead, num_layers, sequence_length, dropout=0.1):\n",
    "        super(WeatherTransformer, self).__init__()\n",
    "        self.input_embedding = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, sequence_length, d_model))\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead, num_encoder_layers=num_layers, dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_embedding(x) + self.positional_encoding\n",
    "        x = x.permute(1, 0, 2)  # (batch, sequence, features) -> (sequence, batch, features)\n",
    "        x = self.transformer(x, x)  # Self-attention\n",
    "        x = x.permute(1, 0, 2)  # (sequence, batch, features) -> (batch, sequence, features)\n",
    "        x = x[:, -1, :]  # 마지막 타임스텝의 결과 사용\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 데이터 로드\n",
    "pollutants_data = pd.read_csv(pollutants_path)\n",
    "weather_data = pd.read_csv(weather_path)\n",
    "\n",
    "# 데이터 병합\n",
    "pollutants_data['datetime'] = pd.to_datetime(pollutants_data['datetime'])\n",
    "weather_data['datetime'] = pd.to_datetime(weather_data['datetime'])\n",
    "merged_data = pd.merge(weather_data, pollutants_data, on='datetime', how='inner')\n",
    "\n",
    "# 입력(X)와 출력(Y) 설정\n",
    "input_features = ['CO', 'Nox', 'Sox', 'TSP', 'PM-10', 'VOCs', 'NH3']\n",
    "target_features = ['temp', 'humidity', 'precip', 'windspeed']\n",
    "\n",
    "X = merged_data[input_features].values\n",
    "Y = merged_data[target_features].values\n",
    "\n",
    "# 슬라이딩 윈도우로 시계열 데이터 생성\n",
    "sequence_length = 7\n",
    "def create_sequences(data, target, sequence_length):\n",
    "    X_seq, Y_seq = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X_seq.append(data[i:i+sequence_length])\n",
    "        if target is not None:\n",
    "            Y_seq.append(target[i+sequence_length])  # 다음 시간 스텝 예측\n",
    "    if target is not None:\n",
    "        return np.array(X_seq), np.array(Y_seq)\n",
    "    return np.array(X_seq), None\n",
    "\n",
    "X_seq, Y_seq = create_sequences(X, Y, sequence_length)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_seq, Y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch 텐서 변환\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "# DataLoader 생성\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, Y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, Y_test_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 모델 하이퍼파라미터 설정\n",
    "input_dim = len(input_features)\n",
    "output_dim = len(target_features)\n",
    "d_model = 64\n",
    "nhead = 4\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "\n",
    "# 모델 초기화\n",
    "model = WeatherTransformer(input_dim, output_dim, d_model, nhead, num_layers, sequence_length, dropout)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 학습\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # 검증\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, Y_batch)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss / len(train_loader):.4f}, Test Loss: {test_loss / len(test_loader):.4f}\")\n",
    "\n",
    "# 실제 값과 비교\n",
    "actual_weather = merged_data[target_features].values[sequence_length:]\n",
    "mse = mean_squared_error(actual_weather, predictions)\n",
    "print(f\"Mean Squared Error (MSE) between actual and predicted weather: {mse:.4f}\")\n",
    "\n",
    "# 비교 데이터프레임 생성\n",
    "comparison_df = pd.DataFrame({\n",
    "    'datetime': merged_data['datetime'].iloc[sequence_length:].reset_index(drop=True),\n",
    "    'Actual Temp': actual_weather[:, 0],\n",
    "    'Predicted Temp': predictions[:, 0],\n",
    "    'Actual Humidity': actual_weather[:, 1],\n",
    "    'Predicted Humidity': predictions[:, 1],\n",
    "    'Actual Precip': actual_weather[:, 2],\n",
    "    'Predicted Precip': predictions[:, 2],\n",
    "    'Actual Windspeed': actual_weather[:, 3],\n",
    "    'Predicted Windspeed': predictions[:, 3]\n",
    "})\n",
    "\n",
    "print(comparison_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
